{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7sqtdeLEajC"
      },
      "source": [
        "The data that is used in this project is the WSIROI dataset that's part of the TIGER dataset (https://tiger.grand-challenge.org/). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8B_rCPuZOcA"
      },
      "outputs": [],
      "source": [
        "# Connect the collab file to the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVNWKOEqeiur"
      },
      "outputs": [],
      "source": [
        "# Import everything that's needed for the data exploration\n",
        "from matplotlib import pyplot as plt \n",
        "from matplotlib.patches import Rectangle, Patch\n",
        "from matplotlib.colors import to_rgb\n",
        "from PIL import Image\n",
        "from statistics import mean\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1wiYE2Dbx8Y"
      },
      "outputs": [],
      "source": [
        "# Store the json file with bounding boxes\n",
        "tissue_cells_json = json.load(open(\"/content/drive/Shared drives/TILs/dataset/TIGER/roi-level-annotations/tissue-cells/tiger-coco.json\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjPhUFbLxHoh"
      },
      "source": [
        "# Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BigNqwYWfOvI"
      },
      "outputs": [],
      "source": [
        "# Print the total amount of images in the dataset\n",
        "print(\"There are\", len(tissue_cells_json['images']), \"images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64k5sET9hTnm"
      },
      "outputs": [],
      "source": [
        "# Print the total amount of bounding box annotations\n",
        "print(\"There are\", len(tissue_cells_json['annotations']), \"annotations.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-SgRHcThxDc"
      },
      "outputs": [],
      "source": [
        "# Calculate how many images are annotated with bounding boxes\n",
        "id = []\n",
        "for annotation in tissue_cells_json['annotations']:\n",
        "  id.append(annotation['image_id'])\n",
        "print(len(set(id)), \"images have annotations.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btIdgdYitvTw"
      },
      "outputs": [],
      "source": [
        "# Print some statistics about the annotations\n",
        "ann_per_img = []\n",
        "min, max = 100000, 0\n",
        "for i in range(len(tissue_cells_json['images'])):\n",
        "  ann_per_img.append(id.count(i))\n",
        "  if id.count(i) > max:\n",
        "    max = id.count(i)\n",
        "  if id.count(i) < min:\n",
        "    min = id.count(i)\n",
        "\n",
        "print(\"=== Number of annotations per image ===\")\n",
        "print(\"Mean:\", statistics.mean(ann_per_img), \"\\nMedian:\", statistics.median(ann_per_img), \"\\nStandard deviation:\", statistics.stdev(ann_per_img), \"\\nMax:\", max, \"\\nMin:\", min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M-7LclFOkjc"
      },
      "outputs": [],
      "source": [
        "# Print some statistics about the image size\n",
        "heights = []\n",
        "widths = []\n",
        "hi_g = []\n",
        "wi_g = []\n",
        "\n",
        "hi_k = []\n",
        "wi_k = []\n",
        "min_height, min_width, max_height, max_width = 100000, 100000, 0, 0\n",
        "\n",
        "for image in tissue_cells_json['images']:\n",
        "  heights.append(image['height'])\n",
        "  widths.append(image['width'])\n",
        "  if image['height'] < min_height:\n",
        "    min_height = image['height']\n",
        "  if image['height'] > max_height:\n",
        "    max_height = image['height']\n",
        "  if image['width'] < min_width:\n",
        "    min_width = image['width']\n",
        "  if image['width'] > max_width:\n",
        "    max_width = image['width']\n",
        "  if image['width'] > 800:\n",
        "    wi_g.append(image['width'])\n",
        "  else:\n",
        "    wi_k.append(image['width'])\n",
        "  if image['height'] > 800:\n",
        "    hi_g.append(image['height'])\n",
        "  else:\n",
        "    hi_k.append(image['height'])\n",
        "\n",
        "print(\"=== Size of the images ===\")\n",
        "print(\"Mean height:\", statistics.mean(heights), \", Mean width:\", statistics.mean(widths), \"\\nMedian height:\", statistics.median(heights), \", Median width:\", statistics.median(widths), \n",
        "      \"\\nStandard deviation height:\", statistics.stdev(heights), \", Standard deviation width:\", statistics.stdev(widths), \"\\nMax height:\", max_height, \", Max width:\", max_width, \n",
        "      \"\\nMin height:\", min_height, \", Min width:\", min_width)\n",
        "\n",
        "print(statistics.mean(wi_k), statistics.mean(wi_g))\n",
        "print(statistics.mean(hi_k), statistics.mean(hi_g))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21QoElaeqrgI"
      },
      "outputs": [],
      "source": [
        "# Plot the heights of the images\n",
        "plt.hist(heights, bins = [0,100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500]) \n",
        "plt.title(\"Histogram height\") \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2DuQV4wjodc"
      },
      "outputs": [],
      "source": [
        "# Print the mean height of the small and large images\n",
        "print(\"The mean height of the images with a height > 800:\", statistics.mean(hi_g), \"\\nThe mean height of the images with a height < 800:\", statistics.mean(hi_k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCcY2Z9hrL3C"
      },
      "outputs": [],
      "source": [
        "# Plot the widths of the images\n",
        "plt.hist(widths, bins = [0,100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500]) \n",
        "plt.title(\"Histogram width\") \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWNtZcPwg0Wn"
      },
      "outputs": [],
      "source": [
        "# Print the mean width of the small and large images\n",
        "print(\"The mean width of the images with a width > 800:\", statistics.mean(wi_g), \"\\nThe mean width of the images with a width < 800:\", statistics.mean(wi_k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yomKEQ8z6xU"
      },
      "outputs": [],
      "source": [
        "# Print an image from the dataset with a given id\n",
        "id = 12\n",
        "for image in tissue_cells_json['images']:\n",
        "  if image['id'] == id:\n",
        "    img = image['file_name']\n",
        "    path = \"/content/drive/Shared drives/TILs/dataset/TIGER/roi-level-annotations/tissue-cells/\" + img\n",
        "\n",
        "tissue_cell_img = cv2.imread(path)\n",
        "plt.imshow(tissue_cell_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TdebfMX_And"
      },
      "outputs": [],
      "source": [
        "# Print an image and bounding boxes from the dataset with a given id\n",
        "id = 12\n",
        "for image in tissue_cells_json['images']:\n",
        "  if image['id'] == id:\n",
        "    img = image['file_name']\n",
        "    path = \"/content/drive/Shared drives/TILs/dataset/TIGER/roi-level-annotations/tissue-cells/\" + img\n",
        "\n",
        "image = cv2.imread(path)\n",
        "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
        "ax.imshow(image)\n",
        "\n",
        "annotations = []\n",
        "for annotation in tissue_cells_json['annotations']:\n",
        "  if annotation['image_id'] == id:\n",
        "    annotations.append(annotation)\n",
        "\n",
        "for annotation in annotations:\n",
        "  bbox_centre_x, bbox_centre_y, width, height = annotation['bbox']\n",
        "  patch = Rectangle((bbox_centre_x, bbox_centre_y), width, height, fill=False, linewidth = 2)\n",
        "  ax.add_patch(patch)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6MINjiKsVGr"
      },
      "outputs": [],
      "source": [
        "# Print an image and pixel-wise segmentation from the dataset with a given id\n",
        "colour_label = {\n",
        "    0: 'k', # no label\n",
        "    1: 'c', # invasive tumor\n",
        "    2: 'g', # tumor associated stroma\n",
        "    3: 'y', # in situ tumor\n",
        "    4: 'crimson', # healty glands\n",
        "    5: 'm', # necrosis not in situ\n",
        "    6: 'darkviolet', # inflamed stroma\n",
        "    7: 'mediumblue' # rest\n",
        "}\n",
        "\n",
        "id = 12\n",
        "for image in tissue_cells_json['images']:\n",
        "  if image['id'] == id:\n",
        "    img = image['file_name']\n",
        "    img = img[8:]\n",
        "    path = \"/content/drive/Shared drives/TILs/dataset/TIGER/roi-level-annotations/tissue-cells/masks\" + img\n",
        "\n",
        "image = cv2.imread(path)\n",
        "\n",
        "for label in np.unique(image):\n",
        "  colour = np.multiply(to_rgb(colour_label[label]),256).astype(np.uint8)\n",
        "  mask = (image == list((label,)*3)).all(axis=2)\n",
        "  image[mask] = colour\n",
        "  print(label)\n",
        "\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyw3h6WxrphQ"
      },
      "outputs": [],
      "source": [
        "# Print the amoung of segmentation annotations per category\n",
        "label_list = [0 for i in range(8)]\n",
        "images_paths = [img_dict['file_name'] for img_dict in tissue_cells_json['images']]\n",
        "for image_path in images_paths:\n",
        "  image_path = image_path[8:]\n",
        "  mask_path = \"/content/drive/Shared drives/TILs/dataset/TIGER/roi-level-annotations/tissue-cells/masks\" + image_path\n",
        "  mask = cv2.imread(mask_path)\n",
        "  for label in np.unique(mask):\n",
        "    label_list[label] += 1\n",
        "\n",
        "for i in range(len(label_list)):\n",
        "  print(\"There are\", label_list[i], \"segmentation annotations for category\", i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFZ3PtHexO0q"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGAuDzA3BPSN",
        "outputId": "73187273-d695-4bfe-e7dc-335b89ecc85d"
      },
      "outputs": [],
      "source": [
        "# Import YOLOv5 \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IypmZFJ1H5Ja"
      },
      "outputs": [],
      "source": [
        "# Install torchvision\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojnXyPWpHziL"
      },
      "outputs": [],
      "source": [
        "# Import everyting that's needed for the model training, validation and testing\n",
        "%cd yolov5\n",
        "import torch\n",
        "from yolov5 import utils\n",
        "import torch\n",
        "import utils\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import glob\n",
        "\n",
        "%matplotlib inline\n",
        "display = utils.notebook_init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAin1VpOLav7"
      },
      "outputs": [],
      "source": [
        "# Train the YOLOv5 model using transfer learning\n",
        "!python train.py --img 150 --hyp 'hyp.scratch-high.yaml' --batch 256 --epochs 300 --data '/content/drive/Shared drives/TILs/Project/yolov5/data/data.yaml' --weights 'yolov5m.pt' --project 'runs_tils' --name 'feature_extraction_yolov5m' --cache --freeze 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq1QfzbUN6uL"
      },
      "outputs": [],
      "source": [
        "# Print validation results\n",
        "display.Image(f\"/content/drive/Shared drives/TILs/Project/yolov5/runs_tils/feature_extraction_yolov5m/results.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWqpDKX8aeia"
      },
      "source": [
        "# Model fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA-C3wWZaUjI"
      },
      "outputs": [],
      "source": [
        "# Fine-tune the model\n",
        "!python train.py --img 150 --hyp 'hyp.VOC.yaml' --batch 256 --epochs 150 --data '/content/drive/Shared drives/TILs/Project/yolov5/data/data.yaml' --weights '/content/drive/Shared drives/TILs/Project/yolov5/runs_tils/feature_extraction_yolov5m/weights/best.pt' --project 'runs_tils' --name 'fine-tuning_yolov5m' --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKe0yd-F_MBt"
      },
      "outputs": [],
      "source": [
        "# Print validation results\n",
        "display.Image(f\"/content/drive/Shared drives/TILs/Project/yolov5/runs_tils/fine-tuning_yolov5m/results.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52XKypJ2bUwR"
      },
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zfqg2K0PbcXe"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using an unseen test set\n",
        "!python val.py --img 150 --weights '/content/drive/Shared drives/TILs/Project/yolov5/runs_tils/fine-tuning_yolov5m/weights/best.pt' --batch 256 --data '/content/drive/Shared drives/TILs/Project/yolov5/data/data.yaml' --task test --project 'runs_tils' --name 'validation_on_test_data_yolov5m'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "YjPhUFbLxHoh"
      ],
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
